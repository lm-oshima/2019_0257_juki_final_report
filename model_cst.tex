\subsection{Segmentationモデル}
Segmentationモデルは、前述した通り、SegNetに量子化技術などを加えたLeapMind独自のものを使用している。これは“blueoil”に組み込まれているモデル“LmSegnetV1Quantize”と同等の構成である\footnote{blueoil：https:\slash\slash blue-oil.org}\footnote{blueoil：https:\slash\slash leapmind.io\slash news\slash content\slash 2460}。blueoilとは、LeapMindが持つ技術の粋を集めた組み込み機器向けDeep Learningのオープンソース・開発プラットフォームである。本プラットフォームで開発されたモデルは、FPGA, CPU, GPUなど、様々なデバイスへと実装が可能となっており、その機能は更に日々アップグレードされ続けている。

\subsection{学習・チューニング}
学習時における代表的なパラメーターとして以下を設定し用いた。

\begin{tabbing}
\hspace{40mm}\= \hspace{10mm} \kill
バッチサイズ \>: 32\\
エポック数 \>: 500\\
初期学習率 \>: 0.001\\
学習率変化 \>: 3-step-decay \\
イメージサイズ \>: 128 ×128\\
オーギュメンテーション \>: Blue, Brightness, Color, Contrast, FlipLeftRight, FlipTopBottom\\
\end{tabbing}

バッチサイズ とは、データセットをいくつかのサブセットに分けて1回学習する際のサブセット１つに含まれるデータ数であり、エポック数は、全てのデータセットが学習に使われる回数を示す。例えばデータセットが320枚の場合、上記の設定値では、１回の学習には32枚の画像が使われる。全てのデータセットが学習に１回使われるまでの学習回数は10回で、設定されたエポック数より総学習回数が5000回となる。学習率とは、学習時における誤差パラメータの変更量に相当し、学習工程の 1/3 毎に学習率を1/10 にする手法を取っている。イメージサイズは入力画像の画素数であり、受領した元画像のサイズ1280×960を小さく・正方形にリサイズしている。

オーギュメンテーション・データ拡張とは、元の学習データに対して画像処理を加え、新たな画像を作成することである。この処理自体では、データそのものの特徴量を増やすという効果はないものの、例えば検出したい物体が現実世界とは異なり左寄りになっている・昼間の画像が多い・障害物がなく綺麗に写りすぎている、といった条件において、データの偏りを緩和する効果などがある。今回は、製造工程での使用を念頭に入れ、主に画像の反転や輝度・色味の変化のみを実施している。

\subsection{評価指標}
Segmentationにおける学習結果の評価指標として、モデルにより予測された結果と、対応する教師データのアノテーション結果との比較を行い、検出すべき対象部位の重なり具合・IoU（Intersection over Union）を算出する。図のような例であれば、教師データと検出データで結果が一致している領域は5.0に対し、全ての領域が13であるため、約0.38となる。この指標においては、教師データと検出データが完全に一致していればIoUは1.0となるが、例え教師データの領域内に検出データが全て含まれている・または検出データの領域内に教師データが全て含まれているような状況においても、教師データ・検出データ双方が一致しない部分が少しでもあれば、結果は1.0より小さくなる。このため、IoUは高ければ高いほどモデルの精度は良いとは言えるものの、現実問題として完全に1.0となるケースはあまりなく、また、仮に結果が1.0より低い状況であったとしても実使用上問題が発生するかどうかは実際の推論結果を確認し分析することで判断していくこととなる。今回は、IoUと推論結果両者について評価を実施した。
\\
\begin{figure}[h!]
\begin{center}
\includegraphics[width=80mm]{images/images_merge/IoU.png}
\caption{IoU 計算方法}
\end{center}
\label{fig:iou}
\end{figure}
