\subsection{学習・推論結果}

実験１の学習結果を図12に示す。学習ステップに対するIoUの値は、400ステップ程で高い水準へと収束し、高い水準を維持したまま収束してることがわかる。この結果は学習が問題なく進んでいることを示しており、本取り組みにおけるDeep Learning の適応可能性は十分にあると考えられる。このモデルに対し、推論データを適用し評価を行った。推論結果の一覧は付録に掲載する。概ね所望の領域が十分検出できている一方、図13に示すように“糸残り”のデータに対しては、糸で囲まれた部分を検出領域として誤判定してしまうケースが見られている。このため、苦手な特徴を持つ"糸残り"のデータを学習に追加することで、検出結果の改善ができるか検討を行った。実験２では、実験１の学習データに“糸残り”の特徴を有する画像を10枚追加し、実験３においては、実験２に対し更に20枚追加し、モデルを作成し評価を行った。

\begin{figure}[htbp]
\begin{minipage}{0.5\hsize}
\begin{center}
\includegraphics[width=80mm]{images/images_merge/iou/iou1.png}
\end{center}
\caption{実験1：トレーニングステップに対するIoU}
\label{fig:iou1}
\end{minipage}
\begin{minipage}{0.5\hsize}
\begin{center}
\includegraphics[width=68mm]{images/images_merge/results/JUKI_train_validation_sep/20180907_152826496_739_113_img.png}
\end{center}
\caption{実験１：“糸残り”のデータに対する推論結果}
\label{fig:nokori1}
\end{minipage}
\end{figure} 

実験２,実験３のIoUならびに“糸残り”の特徴に対する推論結果を図に示す。実験１と実験２を比較すると、実験２におけるテストデータのIoUがより滑らかに収束していることが分かる。Deep Learningを使ったシステムを実用化するには、学習データに含まれない未知のデータに対する推論結果の性能、即ち汎化性能が重要となる。このため、実験２の方が実験１に比べ、より汎化性能が高い・より良いモデルとなったと言える。
一方、実験２と実験３を比較すると、実験３における学習データのIoUが揺らいでいる。これは、苦手なデータが増えたことによる影響と考えられる。しかし、テストデータの結果を比べてみると、実験２と実験３で差がなく、モデルとしてみるとより安定性が増している可能性が高い。実際、“糸残り”の特徴に対する推論結果を比べてみると、これまで発生していた誤り部分に改善が見られていることから、より汎化性能が高いモデルができたと考えられる。
また、画像のエッジ部分に凹凸が見られるが、この部分はSegmentationにおいて画像の縮小・拡大を行なっているためであり、スムージングなどの後処理により平滑化が可能となる。

尚、今回は少量の学習データにより実験を行っているが、実使用環境において汎化性能を向上させるには、質の高い学習データの量を増やすことに加え、学習時のパラメータである学習率やバッチサイズ などのチューニングを行うことが必要となる。

\begin{figure}[htbp]
\begin{minipage}{0.5\hsize}
\begin{center}
\includegraphics[width=80mm]{images/images_merge/iou/iou2.png}
\end{center}
\caption{実験２：トレーニングステップに対するIoU}
\label{fig:iou1}
\end{minipage}
\begin{minipage}{0.5\hsize}
\begin{center}
\includegraphics[width=68mm]{images/images_merge/results/JUKI_train_add20190625_validation_sep/20180907_152826496_739_113_img.png}
\end{center}
\caption{実験２：“糸残り”のデータに対する推論結果}
\label{fig:nokori1}
\end{minipage}
\end{figure} 

\begin{figure}[htbp]
\begin{minipage}{0.5\hsize}
\begin{center}
\includegraphics[width=80mm]{images/images_merge/iou/iou3.png}
\end{center}
\caption{実験３：トレーニングステップに対するIoU}
\label{fig:iou1}
\end{minipage}
\begin{minipage}{0.5\hsize}
\begin{center}
\includegraphics[width=68mm]{images/images_merge/results/JUKI_train_add20190626_validation_sep/20180907_152826496_739_113_img.png}
\end{center}
\caption{実験３：“糸残り”のデータに対する推論結果}
\label{fig:nokori1}
\end{minipage}
\end{figure} 

\newpage


\subsection{ハードウェアへの実装評価}

作成したモデルをハードウェアに実装し、処理速度について評価を行った。今回使用するハードウェアとしては、Terasic社により販売されているDE10-Nanoを使用した \footnote{DE10-Nano：https:\slash\slash DE10-Nano.terasic.com}。外観ならびに構成を図に示す。DE10-Nanoには、Intel製のローエンドFPGAであるCycloneV SE \footnote{Cyclone V SE：https:\slash\slash www.intel.co.jp\slash content\slash www\slash jp\slash ja\slash products\slash programmable\slash fpga\slash cyclone-v.html}が搭載されている。CycloneV SEには、同一パッケージ内に28nmプロセスで作成されたFPGAとデュアルコアのARM Cortex-A9が搭載されており、ARMプロセッサ側でLinux OSが動作する構成となっている。Deep Learningモデルを実装する際には、畳み込み演算などの演算処理をFPGA側で行い、画像のリサイズや特徴量の配置といった部分をARM側で行なっている。
処理速度の評価では、DE10-Nanoボード内に保存した画像に対し推論処理を100回実施し、推論結果が得られるまでの時間を計測した後、単位時間に推論処理ができる画像枚数・FPSの算出を行った。今回のモデルを実装し評価した結果、 2.76FPS (1秒間に2.76枚の画像推論処理が可能) が得られた。処理速度は、モデルの層構造・チャネルを調整することで改善が可能である。また、今回の推論画像は入力サイズを128×128 pixelとしているが、単純計算で画像サイズを96×96 pixelとすると処理速度は2倍となる。一方で、推論する画像の画素数が下がるため、精度劣化が生じる可能性がある。

実運用においては、カメラI/Fにおける撮像〜通信や、推論結果を縫製装置に戻すための電文作成・処理・通信といった部分が更に上乗せされるため、必要となる処理性能の算出と性能確保、ハードウェアの選定・コスト算出など、製品化・サービス化へ向けロードマップを踏まえた検討が必要になると考えられる。



\begin{figure}[htbp]
\begin{minipage}{0.5\hsize}
\begin{center}
\includegraphics[width=70mm]{images/de10.png}
\end{center}
\caption{DE10-Nanoボード・外観写真}
\label{fig:de10}
\end{minipage}
\begin{minipage}{0.5\hsize}
\begin{center}
\includegraphics[width=80mm]{images/de10_block.png}
\end{center}
\caption{DE10-Nanoボード・構成}
\label{fig:deblock}
\end{minipage}
\end{figure} 